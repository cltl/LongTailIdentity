{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import csv\n",
    "import regex as re\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import utils\n",
    "import en_coref_md\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gvdb_articles_file = '../../gvdb-aggregated-db/Articles-with-extracted-info.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "se_annotation_file='../data/input/partial/annotation/participants_input.p'\n",
    "se_text_file='../data/input/partial/text/docs.p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load coreference model & resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = en_coref_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentence_offsets(doc):\n",
    "    sent_offsets=[]\n",
    "    for s in doc.sents:\n",
    "        sent_offsets.append(tuple([s.start_char, s.end_char]))\n",
    "    return sent_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 6), (7, 16), (17, 29)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt ='Hello. I am you. Who are you?'\n",
    "doc = nlp(txt)\n",
    "get_sentence_offsets(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emiel_resources_file='../resources/emiel.json'\n",
    "with open (emiel_resources_file, 'r') as f:\n",
    "    emiel_resources=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "students_resources_file='../resources/students.json'\n",
    "with open (students_resources_file, 'r') as f:\n",
    "    students_resources=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CauseOfDeath', 'Residence', 'EducationLevel', 'Ethnicity', 'Religion', 'BirthPlace', 'PastConviction'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_resources.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attributes=['age', 'race', 'gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_most_frequent_words(rdr, attribute):\\n    frequency_count=defaultdict(int)\\n    for row in rdr:\\n        data=json.loads(row[3])\\n        for s in sections:\\n            for participant in data[s]:\\n                if participant[attribute][\\'value\\']:\\n                    value=participant[attribute][\\'value\\'].strip()\\n                    frequency_count[value]+=1\\n    return Counter(frequency_count).most_common(50)\\n    \\nfrequency_count={}\\nwith open(gvdb_articles_file, \\'r\\') as csvfile:\\n    rdr = csv.reader(csvfile, delimiter=\\'\\t\\', quotechar=\\'\"\\')\\n    header=next(rdr)\\n    frequency_count[\\'race\\']=get_most_frequent_words(rdr, \\'race\\')\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def get_most_frequent_words(rdr, attribute):\n",
    "    frequency_count=defaultdict(int)\n",
    "    for row in rdr:\n",
    "        data=json.loads(row[3])\n",
    "        for s in sections:\n",
    "            for participant in data[s]:\n",
    "                if participant[attribute]['value']:\n",
    "                    value=participant[attribute]['value'].strip()\n",
    "                    frequency_count[value]+=1\n",
    "    return Counter(frequency_count).most_common(50)\n",
    "    \n",
    "frequency_count={}\n",
    "with open(gvdb_articles_file, 'r') as csvfile:\n",
    "    rdr = csv.reader(csvfile, delimiter='\\t', quotechar='\"')\n",
    "    header=next(rdr)\n",
    "    frequency_count['race']=get_most_frequent_words(rdr, 'race')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genders={'he': 'male', \n",
    "         'boy': 'male', \n",
    "         'man': 'male', \n",
    "         'dude': 'male',\n",
    "         'guy': 'male',\n",
    "         'male': 'male',\n",
    "         'brother': 'male',\n",
    "         'father': 'male',\n",
    "         'him': 'male',\n",
    "         'himself': 'male',\n",
    "         'she': 'female',\n",
    "         'girl': 'female',\n",
    "         'woman': 'female',\n",
    "         'female': 'female',\n",
    "         'sister': 'female',\n",
    "         'mother': 'female',\n",
    "         'her': 'female',\n",
    "         'herself': 'female'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_attrs=['age','ethnicity', 'religion', 'occupation', 'educationlevel', \n",
    "               'causeofdeath', 'pastconviction', 'birthplace', 'residence']\n",
    "\n",
    "patterns={}\n",
    "pattern_data=defaultdict(dict)\n",
    "\n",
    "for p in pattern_attrs:\n",
    "    patterns[p]=None\n",
    "\n",
    "#tmp_races = set(emiel_resources['ethnicity'])\n",
    "#tmp_races |= set({'black', 'latino', 'white', 'hispanic', 'asian', 'latina', \n",
    "#       'african american', 'filipino', 'african-american', 'latinos',\n",
    "#      'palestinian', 'chinese-american', 'blacks', 'german-iranian'})\n",
    "#tmp_races = \n",
    "pattern_data['ethnicity']=students_resources['Ethnicity']\n",
    "\n",
    "\n",
    "#genders={'male': {'he', 'boy', 'man', 'dude', 'guy', 'male'}, 'female': {'girl', 'woman', 'female'}}\n",
    "\n",
    "pattern_data['occupation']={o:o for o in emiel_resources['occupation-or-social-group']}\n",
    "\n",
    "#religions={o:o for o in (emiel_resources['religion']+students_resources['Religion'])}\n",
    "pattern_data['religion']=students_resources['Religion']\n",
    "\n",
    "pattern_data['educationlevel']=students_resources['EducationLevel']\n",
    "del pattern_data['educationlevel']['a']\n",
    "\n",
    "pattern_data['pastconviction']=students_resources['PastConviction']\n",
    "\n",
    "pattern_data['causeofdeath']=students_resources['CauseOfDeath']\n",
    "\n",
    "pattern_data['birthplace']=students_resources['BirthPlace']\n",
    "\n",
    "pattern_data['residence']=students_resources['Residence']\n",
    "\n",
    "patterns['age']=[r'\\d\\d?-year-old', r', \\d\\d?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Attribute value extractors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Proximity based extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attr_values_extractor(text, people_spans, coref_spans, sentence_offsets, patterns, a_dict=None):\n",
    "    \"\"\"Generic extractor that operates based on patterns.\"\"\"\n",
    "    \n",
    "    extracted_pairs=defaultdict(list)\n",
    "    for pattern in patterns:\n",
    "        r=re.compile(pattern, re.IGNORECASE)\n",
    "        values=r.finditer(text)\n",
    "        for val_found in values:\n",
    "            span=val_found.span()\n",
    "            value=val_found.group()\n",
    "            value=value.replace('-year-old', '').replace(',', '').strip()\n",
    "            if a_dict and value in a_dict:\n",
    "                value=a_dict[value]\n",
    "            person, distance=utils.find_closest_person(span, \n",
    "                                                       people_spans, \n",
    "                                                       coref_spans, \n",
    "                                                       sentence_offsets,\n",
    "                                                       min_dist=1000)\n",
    "            if person:\n",
    "                extracted_pairs[person].append(tuple([distance, value]))\n",
    "    clean_pairs=utils.get_closest_value_per_person(extracted_pairs)\n",
    "    return clean_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pattern_extractor(text, people_spans, coref_spans, sentence_offsets, patterns=None, pattern_data=None):\n",
    "    if patterns: # if there are patterns given, fire the function immediately\n",
    "        return attr_values_extractor(text, people_spans, coref_spans, sentence_offsets, patterns, pattern_data)\n",
    "    \n",
    "    #else create them first\n",
    "    patterns=set()\n",
    "    cs=set(pattern_data.keys())\n",
    "    for o in cs:\n",
    "        patterns.add(r'\\b%s\\b' % o)\n",
    "    return attr_values_extractor(text, people_spans, coref_spans, sentence_offsets, patterns, pattern_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Coreference based extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attr_extractor_coref(clusters, names, values_json, debug=False): #, text, people_spans):\n",
    "    \n",
    "    person_data=defaultdict(list)\n",
    "\n",
    "    if not clusters:\n",
    "        return person_data\n",
    "    \n",
    "    for c in clusters:\n",
    "        mentions=utils.stringify_cluster_mentions(c.mentions)\n",
    "        for person_name in names:\n",
    "            if utils.lookup_person_in_list(person_name, mentions):\n",
    "                for m in c.mentions:\n",
    "                    for txt in [m.text, m.lemma_]:\n",
    "                        if txt.lower() in values_json.keys():\n",
    "                            person_data[person_name].append(values_json[txt.lower()])\n",
    "                            \n",
    "    clean_data={}\n",
    "    for person_name, gs in person_data.items():\n",
    "        c=Counter(gs).most_common(1)[0][0]\n",
    "        clean_data[person_name]=c\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Run extraction of all properties for a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_properties(names, full_text, nlp):\n",
    "    \n",
    "    doc = nlp(full_text)\n",
    "    # run coreference\n",
    "    people_spans, coref_spans, clusters=utils.get_coref_spans(names, full_text, doc)\n",
    "    \n",
    "    sentence_offsets=utils.get_sentence_offsets(doc)\n",
    "    \n",
    "    all_extracted={}\n",
    "    for attribute in pattern_attrs:\n",
    "        all_extracted[attribute]=pattern_extractor(full_text, \n",
    "                                               people_spans, \n",
    "                                               coref_spans, \n",
    "                                               sentence_offsets, \n",
    "                                               pattern_data=pattern_data[attribute],\n",
    "                                               patterns=patterns[attribute])\n",
    "    \n",
    "    all_extracted['gender']=attr_extractor_coref(clusters, names, genders)\n",
    "    \n",
    "    #combine extractors\n",
    "    combined=utils.singularize_data(all_extracted)\n",
    "            \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Peter Boer': {'age': '26',\n",
       "  'causeofdeath': 'intentional',\n",
       "  'ethnicity': 'white/caucascian',\n",
       "  'occupation': 'police',\n",
       "  'religion': 'christian',\n",
       "  'residence': 'texas'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test stuff\n",
    "\n",
    "txt='Hello Peter Boer, 26 was shot in church from Houston. The white police guy failed.'\n",
    "names=['Peter Boer']\n",
    "extract_properties(names, txt, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run GVDB extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_gvdb_data(the_file, limit=200):\n",
    "\n",
    "    all_gold_rows=[]\n",
    "    all_sys_rows=[]\n",
    "\n",
    "    with open(the_file, 'r') as csvfile:\n",
    "        rdr = csv.reader(csvfile, delimiter='\\t', quotechar='\"')\n",
    "        header=next(rdr)\n",
    "        \n",
    "        for c, row in enumerate(rdr):\n",
    "            if c==limit: break\n",
    "\n",
    "            full_text=row[2]\n",
    "            data=json.loads(row[3])\n",
    "            part_info=utils.get_participant_info(data)\n",
    "\n",
    "            names=set(part_info.keys())\n",
    "            if not len(names): continue\n",
    "\n",
    "            system_data = extract_properties(names, full_text, nlp)\n",
    "            all_sys_rows.append(system_data)\n",
    "            all_gold_rows.append(part_info)\n",
    "            \n",
    "            c+=1\n",
    "    return all_sys_rows, all_gold_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_sys_rows, all_gold_rows = process_gvdb_data(gvdb_articles_file, limit=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run SE extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_se_data(annotation_file, text_file, limit=200):\n",
    "    all_gold_rows=[]\n",
    "    all_sys_rows=[]\n",
    "\n",
    "    with open(annotation_file, 'rb') as af:\n",
    "        annotations=pickle.load(af)\n",
    "    \n",
    "    with open(text_file, 'rb') as tf:\n",
    "        all_texts_json=pickle.load(tf)\n",
    "        \n",
    "    cnt=0\n",
    "    for doc_id, part_data in annotations.items():\n",
    "    \n",
    "        #if doc_id!='b38b3726bdb8fc28186f88217dfa7c7b': continue\n",
    "        \n",
    "        names=utils.get_names(part_data)\n",
    "        \n",
    "        if doc_id not in all_texts_json:\n",
    "            continue\n",
    "        text_json=all_texts_json[doc_id]\n",
    "        conll_data=text_json['content']\n",
    "        text=utils.conll_to_text(conll_data)\n",
    "        \n",
    "        properties=extract_properties(names, text, nlp)\n",
    "        \n",
    "        all_sys_rows.append(properties)\n",
    "        \n",
    "        part_info=utils.transform_part_info(part_data)\n",
    "        all_gold_rows.append(part_info)\n",
    "        \n",
    "        cnt+=1\n",
    "        if cnt==limit: break\n",
    "        \n",
    "    return all_sys_rows, all_gold_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "african american ad74870db8920e6986b76133117e7a82\n",
      "african american 65d7c38113863b1bc6cee2e0fa38dc6c\n",
      "hispanic/latin a51f975867abd1f18661d858fabf9c3f\n",
      "white/caucascian 4026e33b1c2033fb5433740895842102\n",
      "african american 6bb0bddf01c6230df34d1ce9cd7869a6\n",
      "hispanic/latin 8695354c9046509b209a5aa92f48c199\n",
      "african american 6bb255cee652c51bb6d34444b1a76705\n",
      "african american e95dc411de0c45356810076ce4e50890\n",
      "african american 42ab147825ee27d8a354517061216a91\n",
      "african american 2a7e35c5897effac0205abe1f82af96d\n"
     ]
    }
   ],
   "source": [
    "se_system, se_gold = process_se_data(se_annotation_file, se_text_file, limit=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devin Anderson african american {'Devin Anderson': {'causeofdeath': 'accidental', 'ethnicity': 'african american', 'residence': 'louisiana', 'deathplace': 'louisiana', 'deathdate': '2016', 'age': 'teen 12-17', 'gender': 'male'}, 'Ahmad Antoine': {'residence': 'louisiana', 'ethnicity': 'african american', 'pastconviction': 'no', 'age': 'teen 12-17', 'gender': 'male'}}\n",
      "Ahmad Antoine african american {'Devin Anderson': {'causeofdeath': 'accidental', 'ethnicity': 'african american', 'residence': 'louisiana', 'deathplace': 'louisiana', 'deathdate': '2016', 'age': 'teen 12-17', 'gender': 'male'}, 'Ahmad Antoine': {'residence': 'louisiana', 'ethnicity': 'african american', 'pastconviction': 'no', 'age': 'teen 12-17', 'gender': 'male'}}\n",
      "Alejandro Martinez hispanic/latin {'Alejandro Martinez': {'ethnicity': 'hispanic/latin', 'deathplace': 'texas', 'deathdate': '2016', 'age': 'adult 18-64', 'gender': 'male'}}\n",
      "Bryant Sanchez white/caucascian {'Bryant Sanchez': {'ethnicity': 'white/caucascian', 'residence': 'kansas', 'deathplace': 'kansas', 'deathdate': '2016', 'age': 'adult 18-64', 'gender': 'male'}}\n",
      "Stanley Greene african american {'Antwonia Heyward': {'residence': 'south carolina', 'age': 'adult 18-64', 'gender': 'female'}, 'Brandon Lemar Greene': {'residence': 'south carolina', 'age': 'adult 18-64', 'gender': 'male'}, 'Omar Hamilton': {'residence': 'south carolina', 'age': 'adult 18-64', 'gender': 'male'}, 'Jamar Hamilton': {'residence': 'south carolina', 'age': 'adult 18-64', 'gender': 'male'}, 'Stanley Greene': {'ethnicity': 'african american', 'age': 'adult 18-64', 'gender': 'male'}}\n",
      "Luis Canseco hispanic/latin {'Luis Canseco': {'ethnicity': 'hispanic/latin', 'deathplace': 'california', 'deathdate': '2016', 'age': 'teen 12-17', 'gender': 'male'}}\n",
      "Lydell McLaurin african american {'Lydell McLaurin': {'ethnicity': 'african american', 'deathplace': 'indiana', 'deathdate': '2016', 'age': 'child 0-11', 'gender': 'male'}}\n",
      "James Graham african american {'James Graham': {'residence': 'michigan', 'ethnicity': 'african american', 'age': 'adult 18-64', 'gender': 'male'}}\n",
      "Gary Holmes african american {'Gary Holmes': {'ethnicity': 'african american', 'age': 'adult 18-64', 'gender': 'male'}}\n",
      "Tyre King african american {'Tyre King': {'causeofdeath': 'intentional', 'ethnicity': 'african american', 'educationlevel': 'less than high school', 'pastconviction': 'no', 'deathplace': 'ohio', 'deathdate': '2016', 'age': 'teen 12-17', 'gender': 'male'}}\n",
      "defaultdict(<class 'int'>, {'residence': 403, 'age': 739, 'gender': 756, 'educationlevel': 117, 'causeofdeath': 488, 'deathplace': 565, 'deathdate': 565, 'birthplace': 6, 'pastconviction': 32, 'religion': 17, 'medicalcondition': 8, 'ethnicity': 10})\n"
     ]
    }
   ],
   "source": [
    "count_per_attr=defaultdict(int)\n",
    "for row in se_gold:\n",
    "    for part, data in row.items():\n",
    "        for attr in data.keys():\n",
    "            count_per_attr[attr]+=1\n",
    "            if attr=='ethnicity':\n",
    "                print(part, data[attr], row)\n",
    "print(count_per_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Benchmark extractors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Benchmark GVDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.benchmark_extractors(all_sys_rows, all_gold_rows, attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Benchmark on SemEval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "se_attributes=['age', 'gender', 'pastconviction', 'educationlevel', \n",
    "               'causeofdeath', 'ethnicity', 'religion', 'birthplace', 'residence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_age_to_group(sys_data):\n",
    "    for doc in sys_data:\n",
    "        for part, data in doc.items():\n",
    "            if 'age' in data:\n",
    "                age=int(data['age'])\n",
    "                age_group=None\n",
    "                if age<12:\n",
    "                    age_group='child 0-11'\n",
    "                elif age<18:\n",
    "                    age_group='teen 12-17'\n",
    "                elif age<65:\n",
    "                    age_group='adult 18-64'\n",
    "                else:\n",
    "                    age_group='senior 65+'\n",
    "                data['age']=age_group\n",
    "    return sys_data\n",
    "\n",
    "if 'age' in se_attributes:\n",
    "    se_system=map_age_to_group(se_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 sys african american\n",
      "129 sys african american\n",
      "135 gold african american\n",
      "135 gold african american\n",
      "176 gold hispanic/latin\n",
      "239 gold white/caucascian\n",
      "270 gold african american\n",
      "294 gold hispanic/latin\n",
      "305 gold african american\n",
      "335 gold african american\n",
      "364 gold african american\n",
      "403 gold african american\n",
      "420 sys african american\n",
      "defaultdict(<class 'int'>, {'age': 192, 'educationlevel': 23, 'gender': 103, 'residence': 96, 'causeofdeath': 87, 'religion': 2, 'pastconviction': 8}) defaultdict(<class 'int'>, {'pastconviction': 76, 'educationlevel': 14, 'causeofdeath': 136, 'residence': 154, 'age': 14, 'birthplace': 1, 'gender': 14, 'ethnicity': 3, 'religion': 2}) defaultdict(<class 'int'>, {'age': 547, 'gender': 653, 'residence': 307, 'causeofdeath': 401, 'educationlevel': 94, 'birthplace': 6, 'pastconviction': 24, 'religion': 15, 'ethnicity': 10})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'age': 0.9320388349514563,\n",
       "  'birthplace': 0.0,\n",
       "  'causeofdeath': 0.3901345291479821,\n",
       "  'educationlevel': 0.6216216216216216,\n",
       "  'ethnicity': 0.0,\n",
       "  'gender': 0.8803418803418803,\n",
       "  'pastconviction': 0.09523809523809523,\n",
       "  'religion': 0.5,\n",
       "  'residence': 0.384},\n",
       " {'age': 0.2598105548037889,\n",
       "  'birthplace': 0.0,\n",
       "  'causeofdeath': 0.17827868852459017,\n",
       "  'educationlevel': 0.19658119658119658,\n",
       "  'ethnicity': 0.0,\n",
       "  'gender': 0.13624338624338625,\n",
       "  'pastconviction': 0.25,\n",
       "  'religion': 0.11764705882352941,\n",
       "  'residence': 0.23821339950372208},\n",
       " {'age': 0.4063492063492063,\n",
       "  'birthplace': 0.0,\n",
       "  'causeofdeath': 0.24472573839662448,\n",
       "  'educationlevel': 0.29870129870129875,\n",
       "  'ethnicity': 0.0,\n",
       "  'gender': 0.23596792668957617,\n",
       "  'pastconviction': 0.13793103448275862,\n",
       "  'religion': 0.19047619047619047,\n",
       "  'residence': 0.2940275650842266})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.benchmark_extractors(se_system, se_gold, se_attributes, debug='ethnicity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Next steps:\n",
    "* prepare output for extrinsic evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Prepare SE output to be run by the baselines\n",
    "Desired format: pickle\n",
    "{\n",
    "    doc_id:\n",
    "    {\n",
    "        part_id:\n",
    "        {\n",
    "            prop: value, \n",
    "            prop2: value2,\n",
    "            ...\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
