{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import csv\n",
    "import regex as re\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import utils\n",
    "import en_coref_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gvdb_articles_file = '../../gvdb-aggregated-db/Articles-with-extracted-info.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load coreference model & resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = en_coref_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emiel_resources_file='../resources/emiel.json'\n",
    "with open (emiel_resources_file, 'r') as f:\n",
    "    emiel_resources=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "students_resources_file='../resources/students.json'\n",
    "with open (students_resources_file, 'r') as f:\n",
    "    students_resources=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CauseOfDeath', 'Residence', 'EducationLevel', 'Ethnicity', 'Religion', 'BirthPlace', 'PastConviction'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_resources.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attributes=['age', 'race', 'gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_most_frequent_words(rdr, attribute):\\n    frequency_count=defaultdict(int)\\n    for row in rdr:\\n        data=json.loads(row[3])\\n        for s in sections:\\n            for participant in data[s]:\\n                if participant[attribute][\\'value\\']:\\n                    value=participant[attribute][\\'value\\'].strip()\\n                    frequency_count[value]+=1\\n    return Counter(frequency_count).most_common(50)\\n    \\nfrequency_count={}\\nwith open(gvdb_articles_file, \\'r\\') as csvfile:\\n    rdr = csv.reader(csvfile, delimiter=\\'\\t\\', quotechar=\\'\"\\')\\n    header=next(rdr)\\n    frequency_count[\\'race\\']=get_most_frequent_words(rdr, \\'race\\')\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def get_most_frequent_words(rdr, attribute):\n",
    "    frequency_count=defaultdict(int)\n",
    "    for row in rdr:\n",
    "        data=json.loads(row[3])\n",
    "        for s in sections:\n",
    "            for participant in data[s]:\n",
    "                if participant[attribute]['value']:\n",
    "                    value=participant[attribute]['value'].strip()\n",
    "                    frequency_count[value]+=1\n",
    "    return Counter(frequency_count).most_common(50)\n",
    "    \n",
    "frequency_count={}\n",
    "with open(gvdb_articles_file, 'r') as csvfile:\n",
    "    rdr = csv.reader(csvfile, delimiter='\\t', quotechar='\"')\n",
    "    header=next(rdr)\n",
    "    frequency_count['race']=get_most_frequent_words(rdr, 'race')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_races = set(emiel_resources['ethnicity'])\n",
    "tmp_races |= set({'black', 'latino', 'white', 'hispanic', 'asian', 'latina', \n",
    "       'african american', 'filipino', 'african-american', 'latinos',\n",
    "      'palestinian', 'chinese-american', 'blacks', 'german-iranian'})\n",
    "tmp_races |= set(students_resources['Ethnicity'])\n",
    "\n",
    "races={o:o for o in tmp_races}\n",
    "\n",
    "\n",
    "#genders={'male': {'he', 'boy', 'man', 'dude', 'guy', 'male'}, 'female': {'girl', 'woman', 'female'}}\n",
    "\n",
    "genders={'he': 'male', \n",
    "         'boy': 'male', \n",
    "         'man': 'male', \n",
    "         'dude': 'male',\n",
    "         'guy': 'male',\n",
    "         'male': 'male',\n",
    "         'brother': 'male',\n",
    "         'father': 'male',\n",
    "         'him': 'male',\n",
    "         'himself': 'male',\n",
    "         'she': 'female',\n",
    "         'girl': 'female',\n",
    "         'woman': 'female',\n",
    "         'female': 'female',\n",
    "         'sister': 'female',\n",
    "         'mother': 'female',\n",
    "         'her': 'female',\n",
    "         'herself': 'female'}\n",
    "\n",
    "occupations={o:o for o in emiel_resources['occupation-or-social-group']}\n",
    "\n",
    "#religions={o:o for o in (emiel_resources['religion']+students_resources['Religion'])}\n",
    "religions={o:o for o in students_resources['Religion']}\n",
    "\n",
    "educations=students_resources['EducationLevel']\n",
    "del educations['a']\n",
    "\n",
    "convictions=students_resources['PastConviction']\n",
    "\n",
    "causes=students_resources['CauseOfDeath']\n",
    "\n",
    "age_patterns=[r'\\d\\d?-year-old', r', \\d\\d?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Attribute value extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attr_values_extractor(text, people_spans, patterns, a_dict=None):\n",
    "    \"\"\"Generic extractor that operates based on patterns.\"\"\"\n",
    "    \n",
    "    extracted_pairs=defaultdict(list)\n",
    "    for pattern in patterns:\n",
    "        r=re.compile(pattern, re.IGNORECASE)\n",
    "        values=r.finditer(text)\n",
    "        for val_found in values:\n",
    "            span=val_found.span()\n",
    "            value=val_found.group()\n",
    "            value=value.replace('-year-old', '').replace(',', '').strip()\n",
    "            if a_dict and value in a_dict:\n",
    "                value=a_dict[value]\n",
    "            person, distance=utils.find_closest_person(span, people_spans)\n",
    "            if person:\n",
    "                extracted_pairs[person].append(tuple([distance, value]))\n",
    "    clean_pairs=utils.get_closest_value_per_person(extracted_pairs)\n",
    "    return clean_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def age_extractor(text, people_spans):\n",
    "    patterns=[r'\\d\\d?-year-old', r', \\d\\d?']\n",
    "    return attr_values_extractor(text, people_spans, patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pattern_extractor(text, people_spans, patterns=None, pattern_data=None):\n",
    "    if patterns: # if there are patterns given, fire the function immediately\n",
    "        return attr_values_extractor(text, people_spans, patterns, pattern_data)\n",
    "    #else create them first\n",
    "    patterns=set()\n",
    "    cs=set(pattern_data.keys())\n",
    "    for o in cs:\n",
    "        patterns.add(r'\\b%s\\b' % o)\n",
    "    return attr_values_extractor(text, people_spans, patterns, pattern_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attr_extractor_coref(clusters, names, values_json, debug=False): #, text, people_spans):\n",
    "    \n",
    "    person_data=defaultdict(list)\n",
    "\n",
    "    if not clusters:\n",
    "        return person_data\n",
    "    \n",
    "    for c in clusters:\n",
    "        mentions=utils.stringify_cluster_mentions(c.mentions)\n",
    "        for person_name in names:\n",
    "            if utils.lookup_person_in_list(person_name, mentions):\n",
    "                for m in c.mentions:\n",
    "                    for txt in [m.text, m.lemma_]:\n",
    "                        if txt.lower() in values_json.keys():\n",
    "                            person_data[person_name].append(values_json[txt.lower()])\n",
    "                            \n",
    "    clean_data={}\n",
    "    for person_name, gs in person_data.items():\n",
    "        c=Counter(gs).most_common(1)[0][0]\n",
    "        clean_data[person_name]=c\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_properties(names, full_text, nlp):\n",
    "    \n",
    "    # run coreference\n",
    "    people_spans, clusters=utils.get_coref_spans(names, full_text, nlp)\n",
    "\n",
    "    # run individual extractors\n",
    "    gender_extracted=attr_extractor_coref(clusters, names, genders)\n",
    "\n",
    "    age_extracted=pattern_extractor(full_text,people_spans, patterns=age_patterns)\n",
    "    race_extracted=pattern_extractor(full_text,people_spans, pattern_data=races)\n",
    "\n",
    "    occupation_extracted=pattern_extractor(full_text,people_spans, pattern_data=occupations)\n",
    "    #attr_extractor_coref(clusters, names, occupations)\n",
    "    #print(occupation_extracted)\n",
    "    \n",
    "    religion_extracted=pattern_extractor(full_text, people_spans, pattern_data=religions)\n",
    "#    religion_extracted=attr_extractor_coref(clusters, names, religions)\n",
    "    if religion_extracted:\n",
    "        print(religion_extracted)\n",
    "    \n",
    "    education_extracted=pattern_extractor(full_text, people_spans, pattern_data=educations)\n",
    "    #education_extracted=attr_extractor_coref(clusters, names, educations)\n",
    "    if education_extracted:\n",
    "        print(education_extracted)\n",
    "        \n",
    "    conviction_extracted=pattern_extractor(full_text, people_spans, pattern_data=convictions)\n",
    "    #conviction_extracted=attr_extractor_coref(clusters, names, convictions)\n",
    "    if conviction_extracted:\n",
    "        print(conviction_extracted)\n",
    "    \n",
    "    causes_extracted=pattern_extractor(full_text, people_spans, pattern_data=causes)\n",
    "    if causes_extracted:\n",
    "        print(causes_extracted)  \n",
    "    \n",
    "    all_extracted={'age': age_extracted, 'race': race_extracted, 'gender': gender_extracted, \n",
    "                  'religion': religion_extracted, 'occupation': occupation_extracted, \n",
    "                   'education': education_extracted}\n",
    "    \n",
    "    #combine extractors\n",
    "    combined=utils.singularize_data(all_extracted)\n",
    "            \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_gvdb_data(the_file, limit=200):\n",
    "\n",
    "    all_gold_rows=[]\n",
    "    all_sys_rows=[]\n",
    "\n",
    "    with open(the_file, 'r') as csvfile:\n",
    "        rdr = csv.reader(csvfile, delimiter='\\t', quotechar='\"')\n",
    "        header=next(rdr)\n",
    "        \n",
    "        for c, row in enumerate(rdr):\n",
    "            if c==limit: break\n",
    "\n",
    "            full_text=row[2]\n",
    "            data=json.loads(row[3])\n",
    "            part_info=utils.get_participant_info(data)\n",
    "\n",
    "            names=set(part_info.keys())\n",
    "            if not len(names): continue\n",
    "\n",
    "            system_data = extract_properties(names, full_text, nlp)\n",
    "            all_sys_rows.append(system_data)\n",
    "            all_gold_rows.append(part_info)\n",
    "            \n",
    "            c+=1\n",
    "    return all_sys_rows, all_gold_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sean Bolton': 'Intentional'}\n",
      "{'Renea Lloyd': 'Accidental'}\n",
      "{'Michael Habay': 'Intentional'}\n",
      "{'Matthew Moore': 'Yes'}\n",
      "{'Chrystol Moore': 'Intentional'}\n",
      "{'bear': 'Intentional'}\n",
      "{'Kendrick Armond Brown': 'Intentional'}\n"
     ]
    }
   ],
   "source": [
    "all_sys_rows, all_gold_rows = process_gvdb_data(gvdb_articles_file, limit=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Benchmark extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark_extractors(system, gold, attributes):\n",
    "    assert len(system)==len(gold)\n",
    "    tp=defaultdict(int)\n",
    "    fp=defaultdict(int)\n",
    "    fn=defaultdict(int)\n",
    "    \n",
    "    \n",
    "    for index, gold_row in enumerate(gold):\n",
    "        system_row=system[index]\n",
    "        \n",
    "        for part, system_vals in system_row.items():\n",
    "            gold_vals=gold_row[part]\n",
    "            \n",
    "            for a in attributes:\n",
    "                gold_val=''\n",
    "                system_val=''\n",
    "                if a in gold_vals:\n",
    "                    gold_val=gold_vals[a].strip()\n",
    "                if a in system_vals:\n",
    "                    system_val=system_vals[a].strip()\n",
    "                if gold_val and system_val:\n",
    "                    if gold_val==system_val:\n",
    "                        tp[a]+=1\n",
    "                    else:\n",
    "                        fp[a]+=1\n",
    "                        fn[a]+=1\n",
    "                elif gold_val:\n",
    "                    fn[a]+=1\n",
    "                elif system_val:\n",
    "                    fp[a]+=1\n",
    "    \n",
    "    recall={}\n",
    "    prec={}\n",
    "    f1={}\n",
    "    \n",
    "    print(tp,fp, fn)\n",
    "    for a in attributes:\n",
    "        prec[a]=tp[a]/(tp[a]+fp[a])\n",
    "        recall[a]=tp[a]/(tp[a]+fn[a])\n",
    "        f1[a]=2*prec[a]*recall[a]/(prec[a]+recall[a])\n",
    "    return prec, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'age': 96, 'gender': 71, 'race': 1}) defaultdict(<class 'int'>, {'gender': 19, 'age': 1, 'race': 1}) defaultdict(<class 'int'>, {'age': 8, 'gender': 14, 'race': 4})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'age': 0.9896907216494846, 'gender': 0.7888888888888889, 'race': 0.5},\n",
       " {'age': 0.9230769230769231, 'gender': 0.8352941176470589, 'race': 0.2},\n",
       " {'age': 0.955223880597015,\n",
       "  'gender': 0.8114285714285714,\n",
       "  'race': 0.28571428571428575})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_extractors(all_sys_rows, all_gold_rows, attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## * Next steps:\n",
    "* benchmark\n",
    "* other properties: religion, school, deathplace, residence, birthplace, occupation,\n",
    "* evaluate extrinsically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_lexica['religion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
