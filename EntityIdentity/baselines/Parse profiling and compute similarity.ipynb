{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiled_dir='profiler_output'\n",
    "givens_path='%s/given.pkl' % profiled_dir\n",
    "predicted_path='%s/predicted.pkl' % profiled_dir\n",
    "\n",
    "input_dir='../data/input/partial/annotation'\n",
    "\n",
    "output_dir='../data/system/auto_profiling/partial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties=['native language' , 'ethnic group', 'cause of death', 'sex or gender', 'religion', 'member of political party', 'occupation', 'age group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_mapping_file='../resources/gv_mappings.json'\n",
    "with open(value_mapping_file, 'r') as f:\n",
    "    wikidata_to_labels=json.load(f)\n",
    "\n",
    "prop_vals={}\n",
    "for prop, vals in wikidata_to_labels.items():\n",
    "    prop_vals[prop]=list(set(vals.values())) + ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_vals['age group']=['child 0-11', 'teen 12-17', 'adult 18-64', 'senior 65+', '']\n",
    "prop_vals['ethnic group'].append('Hispanic/Latin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parse profiling result\n",
    "\n",
    "#### 1a. Load the profiling predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_profiler_predictions(givens_file, predicted_file, properties):\n",
    "    with open(givens_file, 'rb',) as f:\n",
    "        givens=pickle.load(f, encoding='latin1')\n",
    "    with(open(predicted_file, 'rb')) as f:\n",
    "        predicted=pickle.load(f, encoding='latin1')\n",
    "    \n",
    "    data={}\n",
    "    for index, givens_row in enumerate(givens):\n",
    "        ready_key=[]\n",
    "        ready_value={}\n",
    "        for p in properties:\n",
    "            if p in givens_row.keys():\n",
    "                ready_key.append(givens_row[p])\n",
    "            else:\n",
    "                ready_key.append('')\n",
    "                ready_value[p]=predicted[p][index]\n",
    "        data[tuple(ready_key)]=ready_value\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiled_data=load_profiler_predictions(givens_path, predicted_path, properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b. Merge with existing data to prepare for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_property_tuple(properties, part_data):\n",
    "    part_for_profiler=['']*len(properties)\n",
    "    if 'Ethnicity' in part_data.keys():\n",
    "        v=part_data['Ethnicity'].strip()\n",
    "        if v=='African American':\n",
    "            v='African American/Black'\n",
    "        if v=='White/Caucascian':\n",
    "            v='White/Caucasian'\n",
    "        part_for_profiler[1]=v\n",
    "    if 'CauseOfDeath' in part_data.keys():\n",
    "        part_for_profiler[2]=part_data['CauseOfDeath'].strip()\n",
    "    if 'Gender' in part_data.keys():\n",
    "        part_for_profiler[3]=part_data['Gender'].strip().lower()\n",
    "    if 'Religion' in part_data.keys():\n",
    "        v=part_data['Religion'].strip()\n",
    "        if v=='Christian':\n",
    "            v='Christianity'\n",
    "        part_for_profiler[4]=v\n",
    "    if 'Occupation' in part_data.keys():\n",
    "        part_for_profiler[6]=part_data['Occupation'].strip()\n",
    "    if 'Age' in part_data.keys():\n",
    "        part_for_profiler[7]=part_data['Age'].strip().lower()\n",
    "    tuple_input=tuple(part_for_profiler)\n",
    "\n",
    "    return tuple_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_profiler_data(input_file, properties, profiled_data):\n",
    "    with open(input_file, 'rb') as f:\n",
    "        participants=pickle.load(f)\n",
    "\n",
    "    parts_per_name=defaultdict(dict)\n",
    "    \n",
    "    for doc_id, doc_data in participants.items():\n",
    "        for part_id, part_data in doc_data.items():\n",
    "            name=''\n",
    "            if 'Name' in part_data.keys():\n",
    "                name=part_data['Name']\n",
    "\n",
    "            tuple_input=get_property_tuple(properties, part_data)\n",
    "            values=profiled_data[tuple_input]\n",
    "            \n",
    "            for index, t in enumerate(tuple_input):\n",
    "                if t!='':\n",
    "                    values[properties[index]]=[tuple([t, '1.0'])]\n",
    "            \n",
    "            parts_per_name[name][part_id]=values\n",
    "                \n",
    "    return parts_per_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute similarity with JS entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def js(p, q):\n",
    "    p = np.asarray(p).astype(np.float)\n",
    "    q = np.asarray(q).astype(np.float)\n",
    "   # normalize\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "    m = (p + q) / 2\n",
    "    return (entropy(p, m) + entropy(q, m)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_values(v1, v2, domain):\n",
    "    l=len(domain)\n",
    "    mapped1=[0]*l\n",
    "    mapped2=[0]*l\n",
    "    \n",
    "    for k,v in v1:\n",
    "        index=domain.index(k)\n",
    "        mapped1[index]=v\n",
    "    for k,v in v2:\n",
    "        index=domain.index(k)\n",
    "        mapped2[index]=v\n",
    "    return mapped1, mapped2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_js_divergences(c1, c2, properties):\n",
    "    divs=[]\n",
    "    for p in properties:\n",
    "        mapped1, mapped2 = map_values(c1[p], c2[p], prop_vals[p])\n",
    "        div=js(mapped1, mapped2)\n",
    "        divs.append(div)\n",
    "    return divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "def cluster_matrix_with_features(matrix, algorithm='ward', max_d=0.3, criterion='distance'):\n",
    "    merges = linkage(matrix, 'ward')\n",
    "    clusters = fcluster(merges, max_d, criterion=criterion)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_matrix(distances, eps=0.5, min_samples=1):\n",
    "    labels=DBSCAN(min_samples=min_samples, metric='precomputed').fit_predict(distances)\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = list(labels).count(-1)\n",
    "        \n",
    "    return list(labels), n_clusters, n_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clusters(candidates, properties, start_id):\n",
    "\n",
    "    # intitialize an empty matrix\n",
    "    num_cands=len(candidates.keys())\n",
    "    dist_matrix = np.zeros(shape=(num_cands, num_cands)) # Distances matrix\n",
    "    \n",
    "    # fill the matrix with similarity values\n",
    "    the_keys=list(candidates.keys())    \n",
    "    for index1, p1 in enumerate(the_keys):\n",
    "        for index2, p2 in enumerate(the_keys):\n",
    "            if index1<index2:\n",
    "                c1=candidates[p1]\n",
    "                c2=candidates[p2]\n",
    "                divs=compute_js_divergences(c1, c2, properties)\n",
    "                avg_div=sum(divs)/len(divs)\n",
    "        \n",
    "                dist_matrix[index1, index2]=avg_div\n",
    "                dist_matrix[index2, index1]=avg_div\n",
    "                \n",
    "    # run clustering\n",
    "    clusters, n_clusters, n_noise = cluster_matrix(dist_matrix)\n",
    "    clusters_json={}\n",
    "    for index, part_id in enumerate(the_keys):\n",
    "        cluster_id=start_id+int(clusters[index])\n",
    "        clusters_json[part_id]=cluster_id\n",
    "    \n",
    "    new_start_id=start_id+n_clusters\n",
    "    \n",
    "    if num_cands>1:\n",
    "        print(dist_matrix)\n",
    "        print(num_cands, '\\t', n_clusters)\n",
    "        print(candidates)\n",
    "        input('continue')\n",
    "    \n",
    "    return clusters_json, new_start_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(data, properties):\n",
    "    \n",
    "    clusters={}\n",
    "    start_id=1\n",
    "    for name, name_candidates in data.items():\n",
    "        new_clusters, new_start_id=compute_clusters(name_candidates, properties, start_id)\n",
    "        clusters.update(new_clusters)\n",
    "        start_id=new_start_id\n",
    "    print(start_id)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_clusters(clusters, output_file):\n",
    "    with open(output_file, 'w') as w:\n",
    "        json.dump(clusters, w)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/partial/annotation/participants_input.p\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "2 \t 1\n",
      "{'197305597b1d8d10976862afb0febb8e': {'native language': [('English', 0.9999190856200348), ('Hebrew', 4.5455976036105126e-05), ('French', 3.259447206300881e-05)], 'ethnic group': [('African American/Black', 0.9899308811646633), ('White/Caucasian', 0.01006911883533657), ('', 4.57341775784103e-19)], 'religion': [('Christianity', 0.8841126381019017), ('Judaism', 0.06947726661063709), ('atheism', 0.04202959994518969)], 'member of political party': [('Democratic Party', 0.6939421213559067), ('Republican Party', 0.3060578786440933), ('', 8.692132813342743e-21)], 'occupation': [('actor', 0.9241068213171112), ('politician', 0.03072418620339429), ('journalist', 0.030028258712548838)], 'cause of death': [('Intentional', '1.0')], 'sex or gender': [('male', '1.0')], 'age group': [('teen 12-17', '1.0')]}, 'd8dcbfa71b9b5cf7e3bf283772df7411': {'native language': [('English', 0.9999190856200348), ('Hebrew', 4.5455976036105126e-05), ('French', 3.259447206300881e-05)], 'ethnic group': [('African American/Black', 0.9899308811646633), ('White/Caucasian', 0.01006911883533657), ('', 4.57341775784103e-19)], 'religion': [('Christianity', 0.8841126381019017), ('Judaism', 0.06947726661063709), ('atheism', 0.04202959994518969)], 'member of political party': [('Democratic Party', 0.6939421213559067), ('Republican Party', 0.3060578786440933), ('', 8.692132813342743e-21)], 'occupation': [('actor', 0.9241068213171112), ('politician', 0.03072418620339429), ('journalist', 0.030028258712548838)], 'cause of death': [('Intentional', '1.0')], 'sex or gender': [('male', '1.0')], 'age group': [('teen 12-17', '1.0')]}}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "continue \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "3 \t 1\n",
      "{'22469ebbde972ab665bec2328e3e8281': {'native language': [('English', 0.9673000984105138), ('French', 0.030595477030940323), ('Hebrew', 0.0010869374568688594)], 'ethnic group': [('African American/Black', 0.7619750780950755), ('White/Caucasian', 0.2380249218554192), ('', 2.1793806147360332e-11)], 'cause of death': [('Suicide', 0.621506711543154), ('Accidental', 0.35665820466390846), ('Intentional', 0.021835083773341108)], 'religion': [('Christianity', 0.4938281664690149), ('atheism', 0.40836998022745835), ('Judaism', 0.07335212620033314)], 'member of political party': [('Democratic Party', 0.5470254216223158), ('Republican Party', 0.4529745783677087), ('', 4.743363094052237e-12)], 'occupation': [('actor', 0.6098231818217773), ('singer', 0.12257291202204187), ('journalist', 0.10486667881131201)], 'sex or gender': [('male', '1.0')], 'age group': [('teen 12-17', '1.0')]}, '695f99ae21f8641cc9a3b7ff648a1473': {'native language': [('English', 0.9673000984105138), ('French', 0.030595477030940323), ('Hebrew', 0.0010869374568688594)], 'ethnic group': [('African American/Black', 0.7619750780950755), ('White/Caucasian', 0.2380249218554192), ('', 2.1793806147360332e-11)], 'cause of death': [('Suicide', 0.621506711543154), ('Accidental', 0.35665820466390846), ('Intentional', 0.021835083773341108)], 'religion': [('Christianity', 0.4938281664690149), ('atheism', 0.40836998022745835), ('Judaism', 0.07335212620033314)], 'member of political party': [('Democratic Party', 0.5470254216223158), ('Republican Party', 0.4529745783677087), ('', 4.743363094052237e-12)], 'occupation': [('actor', 0.6098231818217773), ('singer', 0.12257291202204187), ('journalist', 0.10486667881131201)], 'sex or gender': [('male', '1.0')], 'age group': [('teen 12-17', '1.0')]}, 'b0a0251c68d927d4f5ae0ae5d2473018': {'native language': [('English', 0.9673000984105138), ('French', 0.030595477030940323), ('Hebrew', 0.0010869374568688594)], 'ethnic group': [('African American/Black', 0.7619750780950755), ('White/Caucasian', 0.2380249218554192), ('', 2.1793806147360332e-11)], 'cause of death': [('Suicide', 0.621506711543154), ('Accidental', 0.35665820466390846), ('Intentional', 0.021835083773341108)], 'religion': [('Christianity', 0.4938281664690149), ('atheism', 0.40836998022745835), ('Judaism', 0.07335212620033314)], 'member of political party': [('Democratic Party', 0.5470254216223158), ('Republican Party', 0.4529745783677087), ('', 4.743363094052237e-12)], 'occupation': [('actor', 0.6098231818217773), ('singer', 0.12257291202204187), ('journalist', 0.10486667881131201)], 'sex or gender': [('male', '1.0')], 'age group': [('teen 12-17', '1.0')]}}\n"
     ]
    }
   ],
   "source": [
    "for f in glob.glob('%s/*.p' % input_dir):\n",
    "    print(f)\n",
    "    output_file='%s/%s.json' % (output_dir, (f.split('/')[-1]).split('.')[0])\n",
    "    data=prepare_profiler_data(f, properties, profiled_data)\n",
    "    clusters=perform_clustering(data, properties)\n",
    "    store_clusters(clusters, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
