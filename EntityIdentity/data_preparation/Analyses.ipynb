{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import sys\n",
    "import utils\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path='../data/input'\n",
    "gva_input_annotations_file = '%s/annotation/participants_input.p' % input_path\n",
    "gva_samefirstname_annotations = '%s/annotation/participants_samefirstname.p' % input_path\n",
    "gva_samelastname_annotations = '%s/annotation/participants_samelastname.p' % input_path\n",
    "\n",
    "aux_path='auxiliary_data'\n",
    "str_data_path='%s/str_data.json' % aux_path\n",
    "doc2inc_file='%s/doc2inc.p' % aux_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Find participants with multiple incidents\n",
    "\n",
    "The original purpose of this was to find good examples for participants where the profiling could help establishing identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_set=utils.get_all_names_set(gva_input_annotations_file)\n",
    "len(names_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_list=utils.get_all_names_list(gva_input_annotations_file)\n",
    "len(names_list)\n",
    "cntr=Counter(names_list).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open (str_data_path) as f:\n",
    "    str_data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vincent Wainwright {'409732', '479709'}\n",
      "Henry Jackson {'533821', '97407'}\n",
      "Carl Johnson {'321156', '448419'}\n",
      "Quanisha Sims {'558601', '558618'}\n",
      "Omar Hamilton {'767876', '296327'}\n",
      "Daniel Munoz {'494072', '384047'}\n",
      "Allen Troyer {'389279', '502850'}\n",
      "Saeve Evans {'710200', '172205'}\n",
      "Tyquone Greer {'113247', '113214'}\n",
      "Ismael Moreno Jr. {'152722', '156813'}\n",
      "Ronald Williams {'481229', '510769', '387194', '588835'}\n",
      "Rakim Watson {'510769', '588835', '317165'}\n",
      "Lawrence Anderson {'735589', '732572'}\n"
     ]
    }
   ],
   "source": [
    "part_incidents_pairs=0\n",
    "for participant_name, freq in cntr:\n",
    "    participant_name=participant_name.strip()\n",
    "    incs=set()\n",
    "    for inc, parts in str_data.items():\n",
    "        for part in parts:\n",
    "            if 'Name' in part and part['Name'].strip()==participant_name:\n",
    "                incs.add(inc)\n",
    "    if len(incs)>1:\n",
    "        print(participant_name, incs)\n",
    "    part_incidents_pairs+=len(incs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_incidents_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] Fix the data, by: merging the same participants with different names, and by adding BU data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute ambiguity for the various datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguity:\n",
      "1.0350877192982457\n"
     ]
    }
   ],
   "source": [
    "print('Ambiguity:')\n",
    "print(part_incidents_pairs/len(names_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_set_samefirst=utils.get_all_names_set(gva_samefirstname_annotations)\n",
    "len(names_set_samefirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4523076923076923\n"
     ]
    }
   ],
   "source": [
    "print(part_incidents_pairs/len(names_set_samefirst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_set_samelast=utils.get_all_names_set(gva_samelastname_annotations)\n",
    "len(names_set_samelast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2519893899204244\n"
     ]
    }
   ],
   "source": [
    "print(part_incidents_pairs/len(names_set_samelast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inspect GVDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gvdb_articles_path = \"../../gvdb-aggregated-db/Articles-with-extracted-info.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open(gvdb_articles_path) as f:\n",
    "gvdb_articles = pd.read_csv(gvdb_articles_path, sep='\\t')\n",
    "#    csv.reader(f, delimiter='\\t', quotechar='\"')\n",
    "#    print(len(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23903"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gvdb_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sections=['shooter-section', 'victim-section']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt_attr_values=0\n",
    "attr='gender'\n",
    "values=[]\n",
    "states=[]\n",
    "dates=[]\n",
    "for index, row in gvdb_articles.iterrows():\n",
    "    annotations=json.loads(row['Json'])\n",
    "    if annotations['date-and-time']['state']:\n",
    "        states.append(annotations['date-and-time']['state'].strip())\n",
    "    if annotations['date-and-time']['date']:\n",
    "        dates.append(annotations['date-and-time']['date'].strip()[:4])\n",
    "    \n",
    "    #print(annotations)\n",
    "    #break\n",
    "    for sec in sections:\n",
    "#        print(annotations[sec])\n",
    "        for part in annotations[sec]:\n",
    "            if part[attr]:#['value']:\n",
    "                #print(part[attr]['value'])\n",
    "                cnt_attr_values+=1\n",
    "                values.append(part[attr].lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36574"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_attr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male \t 31980\n",
      "female \t 4594\n"
     ]
    }
   ],
   "source": [
    "for v in Counter(values).most_common():\n",
    "    print(v[0],'\\t', v[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA - California \t 3514\n",
      "Unclear \t 3337\n",
      "CO - Colorado \t 3012\n",
      "CT - Connecticut \t 1322\n",
      "Colorado \t 1291\n",
      "PA - Pennsylvania \t 960\n",
      "Connecticut \t 659\n",
      "IL - Illinois \t 610\n",
      "TN - Tennessee \t 466\n",
      "TX - Texas \t 452\n",
      "FL - Florida \t 395\n",
      "NY - New York \t 387\n",
      "OH - Ohio \t 376\n",
      "NJ - New Jersey \t 306\n",
      "IN - Indiana \t 282\n",
      "VA - Virginia \t 260\n",
      "GA - Georgia \t 258\n",
      "NC - North Carolina \t 252\n",
      "WI - Wisconsin \t 229\n",
      "LA - Louisiana \t 218\n",
      "MI - Michigan \t 207\n",
      "Outside the USA \t 202\n",
      "SC - South Carolina \t 187\n",
      "MO - Missouri \t 175\n",
      "MN - Minnesota \t 169\n",
      "AL - Alabama \t 157\n",
      "MD - Maryland \t 153\n",
      "AZ - Arizona \t 122\n",
      "IL \t 121\n",
      "MS - Mississippi \t 111\n",
      "MA - Massachusetts \t 105\n",
      "OK - Oklahoma \t 104\n",
      "Tennessee \t 95\n",
      "Wyo \t 94\n",
      "WA - Washington \t 94\n",
      "KS - Kansas \t 88\n",
      "KY - Kentucky \t 85\n",
      "NV - Nevada \t 83\n",
      "Tenn \t 70\n",
      "CA \t 69\n",
      "AR - Arkansas \t 67\n",
      "DE - Delaware \t 64\n",
      "OR - Oregon \t 54\n",
      "IA - Iowa \t 48\n",
      "WV - West Virginia \t 47\n",
      "N.J. \t 46\n",
      "UT - Utah \t 45\n",
      "MT - Montana \t 44\n",
      "ND - North Dakota \t 37\n",
      "DC - District of Columbia \t 34\n",
      "NM - New Mexico \t 33\n",
      "AK - Alaska \t 31\n",
      "NE - Nebraska \t 29\n",
      "WY - Wyoming \t 27\n",
      "Colorado- \t 25\n",
      "New Jersey \t 24\n",
      "North Colorado \t 23\n",
      "RI - Rhode Island \t 23\n",
      "Louisiana \t 22\n",
      "Montana \t 22\n",
      "Tenn. \t 22\n",
      "NC \t 21\n",
      "California \t 21\n",
      "HI - Hawaii \t 21\n",
      "Ohio \t 20\n",
      "Florida \t 18\n",
      "Minnesota \t 18\n",
      "NH - New Hampshire \t 18\n",
      "Mo \t 17\n",
      "Texas \t 16\n",
      "Mississippi \t 15\n",
      "TN \t 15\n",
      "South Carolina \t 15\n",
      "Connecticu \t 14\n",
      "N.J \t 14\n",
      "Wyo. \t 13\n",
      "New York \t 13\n",
      "NY \t 12\n",
      "Fla \t 11\n",
      "SC \t 11\n",
      "Va \t 11\n",
      "GA \t 11\n",
      "Miss \t 10\n",
      "Oklahoma \t 10\n",
      "Alabama \t 10\n",
      "Arkansas \t 10\n",
      "Virginia \t 10\n",
      "Kentucky \t 10\n",
      "La \t 9\n",
      "Wash \t 9\n",
      "Oregon \t 9\n",
      "Ind \t 8\n",
      "Indiana \t 8\n",
      "Greeley \t 8\n",
      "Maryland \t 8\n",
      "Michigan \t 8\n",
      "Georgia \t 8\n",
      "VT - Vermont \t 8\n",
      "ME - Maine \t 8\n",
      "Calif. \t 7\n",
      "Illinois \t 7\n",
      "MO \t 7\n",
      "Wis. \t 7\n",
      "Miss. \t 7\n",
      "OK \t 7\n",
      "Calif \t 7\n",
      "Iowa \t 7\n",
      "ID - Idaho \t 7\n",
      "Missouri \t 6\n",
      "Pennsylvania \t 6\n",
      "La. \t 6\n",
      "KS \t 6\n",
      "Fla. \t 6\n",
      "SD - South Dakota \t 6\n",
      "Ind. \t 5\n",
      "Okla \t 5\n",
      "N.Y \t 5\n",
      "Ga \t 5\n",
      "Delaware \t 5\n",
      "Utah \t 5\n",
      "LA \t 5\n",
      "Connecticut - \t 5\n",
      "Md \t 5\n",
      "Wash. \t 4\n",
      "Wyoming \t 4\n",
      "North Carolina \t 4\n",
      "OH \t 4\n",
      "New Mexico \t 4\n",
      "VA \t 4\n",
      "Pa \t 4\n",
      "MA \t 4\n",
      "Nevada \t 4\n",
      "Massachusetts \t 4\n",
      "Kansas \t 4\n",
      "WI \t 3\n",
      "IN \t 3\n",
      "AZ \t 3\n",
      "New Orleans \t 3\n",
      "N.Y. \t 3\n",
      "S.C \t 3\n",
      "Washington \t 3\n",
      "OKLAHOMA \t 3\n",
      "Maine \t 3\n",
      "S.C. \t 3\n",
      "Mo. \t 3\n",
      "WA \t 3\n",
      "MT \t 3\n",
      "TX \t 3\n",
      "Wisconsin \t 3\n",
      "AL \t 3\n",
      "N.C. \t 3\n",
      "Idaho \t 3\n",
      "Minn \t 3\n",
      "Ky. \t 3\n",
      "Wilmington, NC \t 3\n",
      "KY \t 2\n",
      ", IL \t 2\n",
      "Atlantic City \t 2\n",
      "Pa. \t 2\n",
      "TENN \t 2\n",
      "Wis \t 2\n",
      "Mich. \t 2\n",
      "Minn. \t 2\n",
      "Va. \t 2\n",
      "Ore \t 2\n",
      "Missouri State \t 2\n",
      "N.M. \t 2\n",
      "Colo. \t 2\n",
      "Ill \t 2\n",
      "Okla. \t 2\n",
      "Greeley, Colorado \t 2\n",
      "Ore. \t 2\n",
      "CA - \t 2\n",
      "Ala. \t 2\n",
      "Md. \t 2\n",
      "Arizona \t 2\n",
      "Ga. \t 2\n",
      "OHIO \t 2\n",
      "Ark \t 2\n",
      "Ala \t 2\n",
      "Dunbar \t 1\n",
      "MS \t 1\n",
      "NC (WECT) \t 1\n",
      "Tn \t 1\n",
      "AK \t 1\n",
      "New Hampshire \t 1\n",
      "Orego \t 1\n",
      "NEW ORLEANS \t 1\n",
      ", N.Y \t 1\n",
      "Nebraska \t 1\n",
      "North Colorado Medical Center \t 1\n",
      "PA \t 1\n",
      "Fl \t 1\n",
      "2015Florida \t 1\n",
      "Western Montana \t 1\n",
      "CT \t 1\n",
      "Tenn., \t 1\n",
      "Ill. \t 1\n",
      "N.C \t 1\n",
      "Conn. \t 1\n",
      "Neb \t 1\n",
      "Trumbull \t 1\n",
      "Memphis \t 1\n",
      "Bridgeport \t 1\n",
      "ID \t 1\n",
      "N.H. \t 1\n",
      "South Florida \t 1\n",
      "Colorad \t 1\n",
      "N.H \t 1\n",
      "- \t 1\n",
      "Connecticut -- Christopher Pettway, the city's ninth homicide victim this year, was recalled Wednesd \t 1\n",
      "Colorado- Greeley \t 1\n",
      "MN \t 1\n",
      ", Colorado- \t 1\n",
      "Pittsburgh \t 1\n",
      "KHBS \t 1\n",
      "Kan \t 1\n",
      "Colorado- Greeley police are investigating a shooting after an adult man showed up at North Colorado \t 1\n",
      "Colo \t 1\n",
      "Neb. \t 1\n",
      "Tennesse \t 1\n",
      "S.D. \t 1\n",
      "olorado \t 1\n",
      "Canada \t 1\n",
      "Conn \t 1\n",
      "CO \t 1\n",
      "Israel \t 1\n",
      "Uganda \t 1\n",
      "Nev. \t 1\n",
      "Denver \t 1\n",
      "West Virginia \t 1\n",
      "District of Columbia \t 1\n",
      "HARTWELL. \t 1\n",
      "TORONTO \t 1\n",
      "Mass \t 1\n",
      "WV \t 1\n",
      ", Colorado \t 1\n"
     ]
    }
   ],
   "source": [
    "for v in Counter(states).most_common():\n",
    "    print(v[0],'\\t', v[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22678"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21578"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 \t 7380\n",
      "2016 \t 7227\n",
      "2014 \t 2423\n",
      "2013 \t 1027\n",
      "2017 \t 432\n",
      "2002 \t 272\n",
      "2005 \t 271\n",
      "2012 \t 263\n",
      "2003 \t 258\n",
      "2008 \t 249\n",
      "2001 \t 244\n",
      "2004 \t 233\n",
      "2006 \t 228\n",
      "2011 \t 228\n",
      "2000 \t 221\n",
      "2010 \t 215\n",
      "2007 \t 206\n",
      "2009 \t 166\n",
      "1969 \t 5\n",
      "1987 \t 4\n",
      "1970 \t 3\n",
      "1942 \t 3\n",
      "1989 \t 3\n",
      "1932 \t 2\n",
      "1999 \t 2\n",
      "1973 \t 2\n",
      "1984 \t 1\n",
      "1929 \t 1\n",
      "1998 \t 1\n",
      "1996 \t 1\n",
      "2026 \t 1\n",
      "1994 \t 1\n",
      "2207 \t 1\n",
      "3009 \t 1\n",
      "2018 \t 1\n",
      "1916 \t 1\n",
      "1995 \t 1\n"
     ]
    }
   ],
   "source": [
    "for v in Counter(dates).most_common():\n",
    "    print(v[0],'\\t', v[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4. Potential for profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(doc2inc_file, 'rb') as f:\n",
    "    doc2inc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unresolvable_pairs_count(participants_file_path):\n",
    "    with open(participants_file_path, 'rb') as f:\n",
    "        gva_data = pickle.load(f)\n",
    "        \n",
    "    c=0\n",
    "    nc=0\n",
    "    for doc_id, data in gva_data.items():\n",
    "        for participant_id, participant_info in data.items():\n",
    "            for doc_id2, data2 in gva_samefirstname.items():\n",
    "                for participant_id2, participant_info2 in data2.items():\n",
    "                    if participant_id2>participant_id and participant_info==participant_info2:\n",
    "                        if debug:\n",
    "                            print(doc2inc[doc_id][0], doc_id, participant_id, participant_info)\n",
    "                            print(doc2inc[doc_id2][0], doc_id2, participant_id2, participant_info2)\n",
    "                            print()\n",
    "                        c+=1\n",
    "                    elif participant_id2>participant_id:\n",
    "                        nc+=1\n",
    "    return c,nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 296823\n"
     ]
    }
   ],
   "source": [
    "count, not_count=unresolvable_pairs_count(gva_input_annotations_file)\n",
    "print(count, not_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 296593\n"
     ]
    }
   ],
   "source": [
    "count, not_count=unresolvable_pairs_count(gva_samefirstname_annotations)\n",
    "print(count, not_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 296823\n"
     ]
    }
   ],
   "source": [
    "count, not_count=unresolvable_pairs_count(gva_samelastname_annotations)\n",
    "print(count, not_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5. Analysis on the entire SE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "se_data_folder='../../semeval18_data'\n",
    "se_test_data_folder='%s/test_data' % se_data_folder\n",
    "se_trial_data_folder='%s/trial_data' % se_data_folder\n",
    "se_frames_file='%s/gva_frames' % se_data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df = pd.read_pickle(se_frames_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4580"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2inc=defaultdict(set)\n",
    "for index, row in a_df.iterrows():\n",
    "    inc_uri=row['incident_uri']\n",
    "    for p in row['participants']:\n",
    "        if 'Name' in p and p['Name']:\n",
    "            name2inc[p['Name'].strip()].add(inc_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jonathan Martinez 2\n",
      "David Anderson 2\n",
      "Carl Johnson 2\n",
      "Daniel Munoz 2\n",
      "Wyatt Krauss 2\n",
      "David Krauss 2\n",
      "Charles Jackson 2\n",
      "Zanyrah Taylor 2\n",
      "Maria Rodriguez 2\n",
      "Henry Jackson 2\n",
      "Ronald Smith 2\n",
      "Tyler Jordan Buchanan 2\n",
      "Joel Rodriguez 2\n",
      "Saeve Evans 2\n",
      "Agent 2\n",
      "Matthew Michael Stevenson 2\n",
      "Omar Hamilton 2\n",
      "Billy Williams 2\n",
      "Cole Kirkpatrick 2\n",
      "Sean Thomas 2\n",
      "Michael Adams 2\n",
      "Justin Anderson 2\n",
      "Juan Trevino 2\n",
      "Lawrence Anderson 2\n",
      "Eric Smith 2\n",
      "Malachi Hemphill 2\n",
      "Allen Troyer 2\n",
      "Quanisha Sims 2\n",
      "Tavarius McKay 2\n",
      "Vincent Wainwright 2\n",
      "Demetrius Davis 2\n",
      "Ronald Williams 4\n",
      "Derrick Jackson 2\n",
      "Ismael Moreno Jr. 2\n",
      "Jordan Harris 2\n",
      "Tyquone Greer 2\n",
      "Mario Oliver 2\n",
      "Jeremy Oliver 2\n",
      "Henry Holloway 2\n",
      "Marcus Oliver 2\n",
      "Robert Holloway 2\n",
      "Ronnie Hendrix 2\n",
      "Elijah Jackson 2\n",
      "Rakim Watson 3\n",
      "Jorge Hernandez 2\n"
     ]
    }
   ],
   "source": [
    "for name, incs in name2inc.items():\n",
    "    if len(incs)>1 and name not in ['Officer', '37', 'Deputy', 'Trooper', 'Detective']:\n",
    "        print(name, len(incs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
