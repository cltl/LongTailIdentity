{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import utils\n",
    "import hashlib\n",
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "se_data_folder='auxiliary_data/semeval18_data'\n",
    "se_test_data_folder='%s/test_data' % se_data_folder\n",
    "se_trial_data_folder='%s/trial_data' % se_data_folder\n",
    "se_frames_file='%s/gva_frames' % se_data_folder\n",
    "\n",
    "input_data_folder='../data/input/full'\n",
    "gold_data_folder='../data/gold/full/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_df = pd.read_pickle(se_frames_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4580"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude_empty_names=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "participant_data_per_document=defaultdict(dict)\n",
    "identical_participants=defaultdict(set)\n",
    "for index, row in a_df.iterrows():\n",
    "    inc_uri=row['incident_uri']\n",
    "    docs=list(row['hashed_ids'].values())\n",
    "    cnt=1\n",
    "    state=row['state']\n",
    "    year=row['date'][-4:]\n",
    "    for participant_data in row['participants']:\n",
    "        inc_part_key='%s#%s' % (inc_uri, cnt)\n",
    "        if exclude_empty_names and \\\n",
    "            ('Name' not in participant_data.keys() or not participant_data['Name'].strip()):\n",
    "            continue\n",
    "        if 'Status' in participant_data:\n",
    "            status=participant_data['Status'].strip()\n",
    "            if status=='Killed':\n",
    "                participant_data['DeathPlace']=state\n",
    "                participant_data['DeathDate']=year\n",
    "        for doc_id in docs:\n",
    "            string_to_encode='%s#%d#%s' % (doc_id, cnt, json.dumps(participant_data))\n",
    "            new_id=hashlib.md5(string_to_encode.encode('utf-8')).hexdigest()\n",
    "            participant_data_per_document[doc_id][new_id]=participant_data\n",
    "            identical_participants[inc_part_key].add(new_id)\n",
    "        cnt+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_participants_file='%s/annotation/participants_input.p' % input_data_folder\n",
    "gold_participants_file='%s/participants_gold.p' % gold_data_folder\n",
    "out_gold_file = '%s/participants.json' % gold_data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(input_participants_file, 'wb') as w:\n",
    "    pickle.dump(participant_data_per_document, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(gold_participants_file, 'wb') as w:\n",
    "    pickle.dump(identical_participants, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_clusters=utils.transform_gold_to_json(identical_participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(out_gold_file, 'w') as w:\n",
    "    json.dump(json_clusters, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Increase ambiguity of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a) Increase ambiguity by giving everyone the same first name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_first_name = \"John\"\n",
    "gva_samefirstname_annotations = '%s/annotation/participants_samefirstname.p' % input_data_folder\n",
    "\n",
    "utils.create_ambiguous_data(input_participants_file, \n",
    "                      gva_samefirstname_annotations, \n",
    "                      new_firstname=new_first_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b) Increase ambiguity by giving everyone the same last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_last_name = \"Smith\"\n",
    "gva_samelastname_annotations = '%s/annotation/participants_samelastname.p' % input_data_folder\n",
    "\n",
    "utils.create_ambiguous_data(input_participants_file, \n",
    "                      gva_samelastname_annotations, \n",
    "                      new_lastname=new_last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) Increase ambiguity by giving everyone the same name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name = \"John Smith\"\n",
    "gva_samename_annotations = '%s/annotation/participants_samename.p' % input_data_folder\n",
    "\n",
    "utils.create_ambiguous_data(input_participants_file, \n",
    "                      gva_samename_annotations, \n",
    "                      new_name=new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gather all documents in JSON format from the violent corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_location='../../../../SemEval/LongTailQATask/EventRegistries/GunViolenceArchive/the_violent_corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_to_store=set(participant_data_per_document.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_documents=set()\n",
    "for fn in glob.glob('%s/*/*.json' % corpus_location):\n",
    "    file_basename=fn.split('/')[-1]\n",
    "    doc_name=file_basename.split('.')[0]\n",
    "    print(doc_name, doc_name in documents_to_store)\n",
    "    if doc_name in documents_to_store and doc_name not in found_documents:\n",
    "        with open(fn, 'rb') as pickfile:\n",
    "            a_news_item=pickle.load(pickfile)\n",
    "        new_json={'title': a_news_item.title, \n",
    "                  'content': a_news_item.content, \n",
    "                  'dct': a_news_item.dct.strftime(\"%Y-%m-%d\")}\n",
    "        with open('%s/text/%s' % (input_data_folder, file_basename), 'w') as target_json:\n",
    "            json.dump(new_json, target_json)\n",
    "        \n",
    "        found_documents.add(doc_name)\n",
    "        print('copied %s' % fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(found_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
