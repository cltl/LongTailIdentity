{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import utils\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux_path='auxiliary_data'\n",
    "all_docs_file = '%s/docs.conll' % aux_path # \n",
    "more_docs_file='%s/new.conll'  % aux_path #\n",
    "relevant_docs_file='%s/final_docs.p'  % aux_path # \n",
    "\n",
    "input_path='../data/input/partial'\n",
    "out_pickle = '%s/text/docs.p' % input_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Get and store texts to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all necessary components\n",
    "all_docs_data=utils.load_conll_data(all_docs_file)\n",
    "\n",
    "more_docs_data=utils.load_conll_data(more_docs_file)\n",
    "\n",
    "with open(relevant_docs_file, 'rb') as f:\n",
    "    relevant_incdocs=pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge initial and added documents\n",
    "for more_doc, more_doc_data in more_docs_data.items():\n",
    "    if more_doc not in all_docs_data.keys():\n",
    "        all_docs_data[more_doc]=more_doc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine document IDs from all incidents\n",
    "relevant_docs=set()\n",
    "for inc, docs in relevant_incdocs.items():\n",
    "    relevant_docs |= set(docs)\n",
    "    \n",
    "print(len(relevant_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the data for the relevant documents\n",
    "docs_data={}\n",
    "for k,v in all_docs_data.items():\n",
    "    if k in relevant_docs:\n",
    "        docs_data[k]=all_docs_data[k]\n",
    "        \n",
    "len(docs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_data['39890c5f9109dcf8e892c4fc6eaa1fd6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_pickle, 'wb') as p:\n",
    "    pickle.dump(docs_data, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Increase ambiguity by giving everyone the same first or last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path='../data/input/partial'\n",
    "gva_input_annotations_file = '%s/annotation/participants_input.p' % input_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a) Increase ambiguity by giving everyone the same first name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_first_name = \"John\"\n",
    "\n",
    "gva_samefirstname_annotations = '%s/annotation/participants_samefirstname.p' % input_path\n",
    "\n",
    "with open(gva_input_annotations_file, 'rb') as f:\n",
    "    gva_input_annotations=pickle.load(f)\n",
    "    for doc_id, data in gva_input_annotations.items():\n",
    "        for participant_id, participant_info in data.items():\n",
    "            if 'Name' in participant_info:\n",
    "                old_name=participant_info['Name']\n",
    "                first_name, *other_names = old_name.split()\n",
    "                participant_info['Name']=' '.join([new_first_name] + other_names)\n",
    "                print(old_name, participant_info[\"Name\"])\n",
    "    with open(gva_samefirstname_annotations, 'wb') as w:\n",
    "        pickle.dump(gva_input_annotations, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b) Increase ambiguity by giving everyone the same last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_last_name = \"Smith\"\n",
    "\n",
    "gva_samelastname_annotations = '%s/annotation/participants_samelastname.p' % input_path\n",
    "\n",
    "with open(gva_input_annotations_file, 'rb') as f:\n",
    "    gva_input_annotations=pickle.load(f)\n",
    "    for doc_id, data in gva_input_annotations.items():\n",
    "        for participant_id, participant_info in data.items():\n",
    "            if 'Name' in participant_info:\n",
    "                old_name=participant_info['Name']\n",
    "                *other_names, last_name = old_name.split()\n",
    "                participant_info['Name']=' '.join(other_names + [new_last_name])\n",
    "                print(old_name, participant_info[\"Name\"])\n",
    "    with open(gva_samelastname_annotations, 'wb') as w:\n",
    "        pickle.dump(gva_input_annotations, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. Transform gold data to JSON with cluster IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "which_partition='partial'\n",
    "gold_file = '../data/gold/%s/participants_gold.p' % which_partition\n",
    "out_gold_file = '../data/gold/%s/participants.json' % which_partition\n",
    "\n",
    "with open(gold_file, 'rb') as g:\n",
    "    gold_data = pickle.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_json=utils.transform_gold_to_json(gold_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(out_gold_file, 'w') as w:\n",
    "    json.dump(gold_json, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
